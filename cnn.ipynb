{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.314914\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 2.312093\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2.327953\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 2.315229\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 2.316190\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 2.278881\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 2.323237\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 2.318270\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2.296824\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 2.308896\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.298671\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 2.289702\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 2.290823\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 2.306070\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 2.292789\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 2.311813\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 2.295906\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 2.291470\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 2.270734\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 2.258509\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.296132\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 2.241886\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 2.238866\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 2.264489\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 2.170077\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.252732\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 2.201634\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 2.246169\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 2.172648\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 2.175260\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.117790\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 2.184182\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 2.122143\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 2.165517\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 2.059104\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 2.117646\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 2.124302\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 2.112034\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 2.024418\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 2.206918\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.048603\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 2.119259\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 2.037344\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 1.915587\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 1.890493\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.993856\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 2.004764\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 2.106329\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 2.022786\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 2.052015\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.079288\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 2.040724\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 2.148962\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 1.988203\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 1.877788\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 2.003559\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 1.947400\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 1.960683\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 1.967039\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 2.053359\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.845953\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 2.099705\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 2.055252\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 1.897003\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 2.086605\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 1.994380\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 1.954050\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 2.052534\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 1.963985\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 2.074535\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.052255\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 1.894029\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 2.049272\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 2.169584\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 2.021153\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 1.885572\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 1.832557\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 1.809837\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 1.971060\n",
      "\n",
      "Test set: Average loss: 1.9088, Accuracy: 3146/10000 (31%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.924407\n",
      "Train Epoch: 2 [640/50000 (1%)]\tLoss: 1.755191\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 2.000549\n",
      "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 1.829305\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 1.903191\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 2.065077\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 1.878814\n",
      "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 1.829777\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 1.939261\n",
      "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 1.955894\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.822021\n",
      "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 1.813517\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 1.877666\n",
      "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 1.814196\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 2.017066\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.884214\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 1.933517\n",
      "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 1.811519\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 1.817860\n",
      "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 1.770704\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 2.050078\n",
      "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 1.847834\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 1.858125\n",
      "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 1.778718\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 1.684415\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 1.941606\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 1.764211\n",
      "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 1.814252\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 1.816095\n",
      "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 1.847212\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.763799\n",
      "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 1.842468\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 1.899007\n",
      "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 1.981738\n",
      "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 1.889345\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.912794\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 1.712173\n",
      "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 1.761842\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 1.827082\n",
      "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 1.601188\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.711366\n",
      "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 1.836645\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 1.773683\n",
      "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 1.698514\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 1.804294\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 1.577201\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 1.712627\n",
      "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 1.964477\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 1.619279\n",
      "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 1.810602\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.730379\n",
      "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 1.861947\n",
      "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 1.865279\n",
      "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 1.749140\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 1.732532\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 1.668679\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 1.578068\n",
      "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 1.775342\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 1.888209\n",
      "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 1.781372\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.829369\n",
      "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 1.807494\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 1.768318\n",
      "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 1.812259\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 1.717703\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 1.493150\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 1.674219\n",
      "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 1.579436\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 1.800835\n",
      "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 1.554956\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.748874\n",
      "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 1.661375\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 1.693562\n",
      "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 1.635600\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 1.642854\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 1.596897\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 1.781685\n",
      "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 1.972261\n",
      "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 1.739541\n",
      "\n",
      "Test set: Average loss: 1.6653, Accuracy: 3965/10000 (40%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.810146\n",
      "Train Epoch: 3 [640/50000 (1%)]\tLoss: 1.739099\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 1.484358\n",
      "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 1.724852\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 1.496086\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 1.510879\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 1.629812\n",
      "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 1.619500\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 1.712432\n",
      "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 1.706865\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.680155\n",
      "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 1.814154\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 1.588058\n",
      "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 1.593100\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 1.533163\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 1.781201\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1.797579\n",
      "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 1.768408\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 1.663328\n",
      "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 1.847872\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.706290\n",
      "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 1.772080\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 1.603494\n",
      "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 1.456407\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1.606776\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 1.720391\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 1.502487\n",
      "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 1.589320\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 1.626670\n",
      "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 1.633405\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.647263\n",
      "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 1.526879\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 1.570326\n",
      "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 1.449593\n",
      "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 1.435783\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 1.475734\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 1.675095\n",
      "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 1.673687\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 1.505515\n",
      "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 1.614622\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.621427\n",
      "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 1.733444\n",
      "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 1.840186\n",
      "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 1.704666\n",
      "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 1.524862\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 1.695860\n",
      "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 1.717677\n",
      "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 1.601217\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 1.896348\n",
      "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 1.558436\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.477879\n",
      "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 1.522943\n",
      "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 1.503139\n",
      "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 1.718128\n",
      "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 1.451872\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 1.546342\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 1.523306\n",
      "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 1.593928\n",
      "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 1.459802\n",
      "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 1.527643\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.522355\n",
      "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 1.480799\n",
      "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 1.642555\n",
      "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 1.533119\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 1.659593\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 1.658055\n",
      "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 1.601424\n",
      "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 1.618461\n",
      "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 1.786806\n",
      "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 1.597556\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.470453\n",
      "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 1.413804\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 1.466103\n",
      "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 1.700727\n",
      "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 1.659441\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 1.679160\n",
      "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 1.584512\n",
      "Train Epoch: 3 [49280/50000 (98%)]\tLoss: 1.407635\n",
      "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 1.393433\n",
      "\n",
      "Test set: Average loss: 1.4813, Accuracy: 4612/10000 (46%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.572772\n",
      "Train Epoch: 4 [640/50000 (1%)]\tLoss: 1.617274\n",
      "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 1.506796\n",
      "Train Epoch: 4 [1920/50000 (4%)]\tLoss: 1.586450\n",
      "Train Epoch: 4 [2560/50000 (5%)]\tLoss: 1.509070\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 1.573316\n",
      "Train Epoch: 4 [3840/50000 (8%)]\tLoss: 1.691306\n",
      "Train Epoch: 4 [4480/50000 (9%)]\tLoss: 1.379759\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 1.616405\n",
      "Train Epoch: 4 [5760/50000 (12%)]\tLoss: 1.437671\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.336036\n",
      "Train Epoch: 4 [7040/50000 (14%)]\tLoss: 1.710829\n",
      "Train Epoch: 4 [7680/50000 (15%)]\tLoss: 1.849202\n",
      "Train Epoch: 4 [8320/50000 (17%)]\tLoss: 1.643262\n",
      "Train Epoch: 4 [8960/50000 (18%)]\tLoss: 1.675896\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 1.720414\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 1.564833\n",
      "Train Epoch: 4 [10880/50000 (22%)]\tLoss: 1.431567\n",
      "Train Epoch: 4 [11520/50000 (23%)]\tLoss: 1.367008\n",
      "Train Epoch: 4 [12160/50000 (24%)]\tLoss: 1.592562\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.778532\n",
      "Train Epoch: 4 [13440/50000 (27%)]\tLoss: 1.800407\n",
      "Train Epoch: 4 [14080/50000 (28%)]\tLoss: 1.573072\n",
      "Train Epoch: 4 [14720/50000 (29%)]\tLoss: 1.544758\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 1.391809\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 1.608201\n",
      "Train Epoch: 4 [16640/50000 (33%)]\tLoss: 1.600376\n",
      "Train Epoch: 4 [17280/50000 (35%)]\tLoss: 1.291460\n",
      "Train Epoch: 4 [17920/50000 (36%)]\tLoss: 1.577959\n",
      "Train Epoch: 4 [18560/50000 (37%)]\tLoss: 1.468824\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.434358\n",
      "Train Epoch: 4 [19840/50000 (40%)]\tLoss: 1.329225\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 1.679093\n",
      "Train Epoch: 4 [21120/50000 (42%)]\tLoss: 1.536618\n",
      "Train Epoch: 4 [21760/50000 (43%)]\tLoss: 1.478483\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 1.454528\n",
      "Train Epoch: 4 [23040/50000 (46%)]\tLoss: 1.638817\n",
      "Train Epoch: 4 [23680/50000 (47%)]\tLoss: 1.471630\n",
      "Train Epoch: 4 [24320/50000 (49%)]\tLoss: 1.563898\n",
      "Train Epoch: 4 [24960/50000 (50%)]\tLoss: 1.659513\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.822460\n",
      "Train Epoch: 4 [26240/50000 (52%)]\tLoss: 1.352738\n",
      "Train Epoch: 4 [26880/50000 (54%)]\tLoss: 1.652693\n",
      "Train Epoch: 4 [27520/50000 (55%)]\tLoss: 1.356418\n",
      "Train Epoch: 4 [28160/50000 (56%)]\tLoss: 1.586653\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 1.480172\n",
      "Train Epoch: 4 [29440/50000 (59%)]\tLoss: 1.472580\n",
      "Train Epoch: 4 [30080/50000 (60%)]\tLoss: 1.784443\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 1.576382\n",
      "Train Epoch: 4 [31360/50000 (63%)]\tLoss: 1.445790\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.260773\n",
      "Train Epoch: 4 [32640/50000 (65%)]\tLoss: 1.355028\n",
      "Train Epoch: 4 [33280/50000 (66%)]\tLoss: 1.480250\n",
      "Train Epoch: 4 [33920/50000 (68%)]\tLoss: 2.047706\n",
      "Train Epoch: 4 [34560/50000 (69%)]\tLoss: 1.361610\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 1.677172\n",
      "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 1.347867\n",
      "Train Epoch: 4 [36480/50000 (73%)]\tLoss: 1.555995\n",
      "Train Epoch: 4 [37120/50000 (74%)]\tLoss: 1.474947\n",
      "Train Epoch: 4 [37760/50000 (75%)]\tLoss: 1.640587\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.436588\n",
      "Train Epoch: 4 [39040/50000 (78%)]\tLoss: 1.629153\n",
      "Train Epoch: 4 [39680/50000 (79%)]\tLoss: 1.534968\n",
      "Train Epoch: 4 [40320/50000 (81%)]\tLoss: 1.592985\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 1.342541\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 1.466025\n",
      "Train Epoch: 4 [42240/50000 (84%)]\tLoss: 1.511723\n",
      "Train Epoch: 4 [42880/50000 (86%)]\tLoss: 1.507488\n",
      "Train Epoch: 4 [43520/50000 (87%)]\tLoss: 1.306035\n",
      "Train Epoch: 4 [44160/50000 (88%)]\tLoss: 1.456984\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.536414\n",
      "Train Epoch: 4 [45440/50000 (91%)]\tLoss: 1.397683\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 1.369310\n",
      "Train Epoch: 4 [46720/50000 (93%)]\tLoss: 1.483211\n",
      "Train Epoch: 4 [47360/50000 (95%)]\tLoss: 1.453512\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 1.688396\n",
      "Train Epoch: 4 [48640/50000 (97%)]\tLoss: 1.578517\n",
      "Train Epoch: 4 [49280/50000 (98%)]\tLoss: 1.464899\n",
      "Train Epoch: 4 [49920/50000 (100%)]\tLoss: 1.326490\n",
      "\n",
      "Test set: Average loss: 1.4181, Accuracy: 4870/10000 (49%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.611504\n",
      "Train Epoch: 5 [640/50000 (1%)]\tLoss: 1.514122\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 1.443853\n",
      "Train Epoch: 5 [1920/50000 (4%)]\tLoss: 1.444908\n",
      "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 1.645006\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 1.380086\n",
      "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 1.441009\n",
      "Train Epoch: 5 [4480/50000 (9%)]\tLoss: 1.423649\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 1.549880\n",
      "Train Epoch: 5 [5760/50000 (12%)]\tLoss: 1.592518\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.484421\n",
      "Train Epoch: 5 [7040/50000 (14%)]\tLoss: 1.578598\n",
      "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 1.470846\n",
      "Train Epoch: 5 [8320/50000 (17%)]\tLoss: 1.331708\n",
      "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 1.540481\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 1.556651\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 1.476478\n",
      "Train Epoch: 5 [10880/50000 (22%)]\tLoss: 1.297349\n",
      "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 1.353201\n",
      "Train Epoch: 5 [12160/50000 (24%)]\tLoss: 1.397266\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.492642\n",
      "Train Epoch: 5 [13440/50000 (27%)]\tLoss: 1.395943\n",
      "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 1.790320\n",
      "Train Epoch: 5 [14720/50000 (29%)]\tLoss: 1.522505\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 1.326034\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 1.496249\n",
      "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 1.382438\n",
      "Train Epoch: 5 [17280/50000 (35%)]\tLoss: 1.461648\n",
      "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 1.683446\n",
      "Train Epoch: 5 [18560/50000 (37%)]\tLoss: 1.348224\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.453150\n",
      "Train Epoch: 5 [19840/50000 (40%)]\tLoss: 1.548072\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 1.663998\n",
      "Train Epoch: 5 [21120/50000 (42%)]\tLoss: 1.559512\n",
      "Train Epoch: 5 [21760/50000 (43%)]\tLoss: 1.418133\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 1.556725\n",
      "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 1.722370\n",
      "Train Epoch: 5 [23680/50000 (47%)]\tLoss: 1.734862\n",
      "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 1.585687\n",
      "Train Epoch: 5 [24960/50000 (50%)]\tLoss: 1.792586\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.575024\n",
      "Train Epoch: 5 [26240/50000 (52%)]\tLoss: 1.384506\n",
      "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 1.519066\n",
      "Train Epoch: 5 [27520/50000 (55%)]\tLoss: 1.407185\n",
      "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 1.912637\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 1.497578\n",
      "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 1.586752\n",
      "Train Epoch: 5 [30080/50000 (60%)]\tLoss: 1.469424\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 1.786379\n",
      "Train Epoch: 5 [31360/50000 (63%)]\tLoss: 1.527828\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.570537\n",
      "Train Epoch: 5 [32640/50000 (65%)]\tLoss: 1.631683\n",
      "Train Epoch: 5 [33280/50000 (66%)]\tLoss: 1.512518\n",
      "Train Epoch: 5 [33920/50000 (68%)]\tLoss: 1.452681\n",
      "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 1.423579\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 1.536776\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 1.481087\n",
      "Train Epoch: 5 [36480/50000 (73%)]\tLoss: 1.520875\n",
      "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 1.474137\n",
      "Train Epoch: 5 [37760/50000 (75%)]\tLoss: 1.432141\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.600761\n",
      "Train Epoch: 5 [39040/50000 (78%)]\tLoss: 1.441542\n",
      "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 1.524397\n",
      "Train Epoch: 5 [40320/50000 (81%)]\tLoss: 1.456612\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 1.276607\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 1.345188\n",
      "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 1.370429\n",
      "Train Epoch: 5 [42880/50000 (86%)]\tLoss: 1.411308\n",
      "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 1.432234\n",
      "Train Epoch: 5 [44160/50000 (88%)]\tLoss: 1.358988\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.423255\n",
      "Train Epoch: 5 [45440/50000 (91%)]\tLoss: 1.474907\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 1.655126\n",
      "Train Epoch: 5 [46720/50000 (93%)]\tLoss: 1.364376\n",
      "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 1.641666\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 1.414852\n",
      "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 1.360149\n",
      "Train Epoch: 5 [49280/50000 (98%)]\tLoss: 1.492680\n",
      "Train Epoch: 5 [49920/50000 (100%)]\tLoss: 1.369208\n",
      "\n",
      "Test set: Average loss: 1.3699, Accuracy: 5125/10000 (51%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.463132\n",
      "Train Epoch: 6 [640/50000 (1%)]\tLoss: 1.482486\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 1.238462\n",
      "Train Epoch: 6 [1920/50000 (4%)]\tLoss: 1.196003\n",
      "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 1.099646\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 1.237647\n",
      "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 1.597500\n",
      "Train Epoch: 6 [4480/50000 (9%)]\tLoss: 1.525114\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 1.272431\n",
      "Train Epoch: 6 [5760/50000 (12%)]\tLoss: 1.304670\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.377735\n",
      "Train Epoch: 6 [7040/50000 (14%)]\tLoss: 1.599463\n",
      "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 1.459523\n",
      "Train Epoch: 6 [8320/50000 (17%)]\tLoss: 1.196036\n",
      "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 1.264181\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 1.697812\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 1.339598\n",
      "Train Epoch: 6 [10880/50000 (22%)]\tLoss: 1.533571\n",
      "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 1.341961\n",
      "Train Epoch: 6 [12160/50000 (24%)]\tLoss: 1.466850\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.141323\n",
      "Train Epoch: 6 [13440/50000 (27%)]\tLoss: 1.285945\n",
      "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 1.706800\n",
      "Train Epoch: 6 [14720/50000 (29%)]\tLoss: 1.522715\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 1.403805\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 1.774938\n",
      "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 1.463912\n",
      "Train Epoch: 6 [17280/50000 (35%)]\tLoss: 1.249633\n",
      "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 1.443049\n",
      "Train Epoch: 6 [18560/50000 (37%)]\tLoss: 1.706818\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.456145\n",
      "Train Epoch: 6 [19840/50000 (40%)]\tLoss: 1.461241\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 1.342399\n",
      "Train Epoch: 6 [21120/50000 (42%)]\tLoss: 1.333552\n",
      "Train Epoch: 6 [21760/50000 (43%)]\tLoss: 1.486109\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 1.448055\n",
      "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 1.460514\n",
      "Train Epoch: 6 [23680/50000 (47%)]\tLoss: 1.530509\n",
      "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 1.196934\n",
      "Train Epoch: 6 [24960/50000 (50%)]\tLoss: 1.412993\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.311882\n",
      "Train Epoch: 6 [26240/50000 (52%)]\tLoss: 1.240322\n",
      "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 1.504344\n",
      "Train Epoch: 6 [27520/50000 (55%)]\tLoss: 1.244886\n",
      "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 1.260232\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 1.384182\n",
      "Train Epoch: 6 [29440/50000 (59%)]\tLoss: 1.559112\n",
      "Train Epoch: 6 [30080/50000 (60%)]\tLoss: 1.266536\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 1.448604\n",
      "Train Epoch: 6 [31360/50000 (63%)]\tLoss: 1.504570\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.443880\n",
      "Train Epoch: 6 [32640/50000 (65%)]\tLoss: 1.444448\n",
      "Train Epoch: 6 [33280/50000 (66%)]\tLoss: 1.331930\n",
      "Train Epoch: 6 [33920/50000 (68%)]\tLoss: 1.394539\n",
      "Train Epoch: 6 [34560/50000 (69%)]\tLoss: 1.439280\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 1.456595\n",
      "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 1.280919\n",
      "Train Epoch: 6 [36480/50000 (73%)]\tLoss: 1.428571\n",
      "Train Epoch: 6 [37120/50000 (74%)]\tLoss: 1.251019\n",
      "Train Epoch: 6 [37760/50000 (75%)]\tLoss: 1.572069\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.536557\n",
      "Train Epoch: 6 [39040/50000 (78%)]\tLoss: 1.445279\n",
      "Train Epoch: 6 [39680/50000 (79%)]\tLoss: 1.287846\n",
      "Train Epoch: 6 [40320/50000 (81%)]\tLoss: 1.482336\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 1.378032\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 1.548314\n",
      "Train Epoch: 6 [42240/50000 (84%)]\tLoss: 1.566911\n",
      "Train Epoch: 6 [42880/50000 (86%)]\tLoss: 1.034563\n",
      "Train Epoch: 6 [43520/50000 (87%)]\tLoss: 1.117002\n",
      "Train Epoch: 6 [44160/50000 (88%)]\tLoss: 1.570214\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.403684\n",
      "Train Epoch: 6 [45440/50000 (91%)]\tLoss: 1.420489\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 1.556938\n",
      "Train Epoch: 6 [46720/50000 (93%)]\tLoss: 1.213390\n",
      "Train Epoch: 6 [47360/50000 (95%)]\tLoss: 1.508286\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 1.376403\n",
      "Train Epoch: 6 [48640/50000 (97%)]\tLoss: 1.451056\n",
      "Train Epoch: 6 [49280/50000 (98%)]\tLoss: 1.424704\n",
      "Train Epoch: 6 [49920/50000 (100%)]\tLoss: 1.258218\n",
      "\n",
      "Test set: Average loss: 1.3535, Accuracy: 5114/10000 (51%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.334001\n",
      "Train Epoch: 7 [640/50000 (1%)]\tLoss: 1.472890\n",
      "Train Epoch: 7 [1280/50000 (3%)]\tLoss: 1.474887\n",
      "Train Epoch: 7 [1920/50000 (4%)]\tLoss: 1.435008\n",
      "Train Epoch: 7 [2560/50000 (5%)]\tLoss: 1.442010\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 1.411821\n",
      "Train Epoch: 7 [3840/50000 (8%)]\tLoss: 1.280324\n",
      "Train Epoch: 7 [4480/50000 (9%)]\tLoss: 1.227446\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 1.623900\n",
      "Train Epoch: 7 [5760/50000 (12%)]\tLoss: 1.381418\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.185181\n",
      "Train Epoch: 7 [7040/50000 (14%)]\tLoss: 1.407410\n",
      "Train Epoch: 7 [7680/50000 (15%)]\tLoss: 1.280196\n",
      "Train Epoch: 7 [8320/50000 (17%)]\tLoss: 1.204420\n",
      "Train Epoch: 7 [8960/50000 (18%)]\tLoss: 1.410532\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 1.484103\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 1.295989\n",
      "Train Epoch: 7 [10880/50000 (22%)]\tLoss: 1.511761\n",
      "Train Epoch: 7 [11520/50000 (23%)]\tLoss: 1.410446\n",
      "Train Epoch: 7 [12160/50000 (24%)]\tLoss: 1.486828\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.238179\n",
      "Train Epoch: 7 [13440/50000 (27%)]\tLoss: 1.450938\n",
      "Train Epoch: 7 [14080/50000 (28%)]\tLoss: 1.422254\n",
      "Train Epoch: 7 [14720/50000 (29%)]\tLoss: 1.263433\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 1.294492\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 1.162450\n",
      "Train Epoch: 7 [16640/50000 (33%)]\tLoss: 1.308337\n",
      "Train Epoch: 7 [17280/50000 (35%)]\tLoss: 1.601352\n",
      "Train Epoch: 7 [17920/50000 (36%)]\tLoss: 1.400291\n",
      "Train Epoch: 7 [18560/50000 (37%)]\tLoss: 1.411240\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.226563\n",
      "Train Epoch: 7 [19840/50000 (40%)]\tLoss: 1.324299\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 1.446348\n",
      "Train Epoch: 7 [21120/50000 (42%)]\tLoss: 1.509326\n",
      "Train Epoch: 7 [21760/50000 (43%)]\tLoss: 1.442291\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 1.252211\n",
      "Train Epoch: 7 [23040/50000 (46%)]\tLoss: 1.462846\n",
      "Train Epoch: 7 [23680/50000 (47%)]\tLoss: 1.298247\n",
      "Train Epoch: 7 [24320/50000 (49%)]\tLoss: 1.400548\n",
      "Train Epoch: 7 [24960/50000 (50%)]\tLoss: 1.348506\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.448048\n",
      "Train Epoch: 7 [26240/50000 (52%)]\tLoss: 1.401046\n",
      "Train Epoch: 7 [26880/50000 (54%)]\tLoss: 1.404939\n",
      "Train Epoch: 7 [27520/50000 (55%)]\tLoss: 1.474597\n",
      "Train Epoch: 7 [28160/50000 (56%)]\tLoss: 1.298993\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 1.424760\n",
      "Train Epoch: 7 [29440/50000 (59%)]\tLoss: 1.488559\n",
      "Train Epoch: 7 [30080/50000 (60%)]\tLoss: 1.103488\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 1.194308\n",
      "Train Epoch: 7 [31360/50000 (63%)]\tLoss: 1.336066\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.295280\n",
      "Train Epoch: 7 [32640/50000 (65%)]\tLoss: 1.376943\n",
      "Train Epoch: 7 [33280/50000 (66%)]\tLoss: 1.206046\n",
      "Train Epoch: 7 [33920/50000 (68%)]\tLoss: 1.777874\n",
      "Train Epoch: 7 [34560/50000 (69%)]\tLoss: 1.328110\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 1.378635\n",
      "Train Epoch: 7 [35840/50000 (72%)]\tLoss: 1.374732\n",
      "Train Epoch: 7 [36480/50000 (73%)]\tLoss: 1.469307\n",
      "Train Epoch: 7 [37120/50000 (74%)]\tLoss: 1.318087\n",
      "Train Epoch: 7 [37760/50000 (75%)]\tLoss: 1.295407\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.431840\n",
      "Train Epoch: 7 [39040/50000 (78%)]\tLoss: 1.547685\n",
      "Train Epoch: 7 [39680/50000 (79%)]\tLoss: 1.328588\n",
      "Train Epoch: 7 [40320/50000 (81%)]\tLoss: 1.411238\n",
      "Train Epoch: 7 [40960/50000 (82%)]\tLoss: 1.522307\n",
      "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 1.563492\n",
      "Train Epoch: 7 [42240/50000 (84%)]\tLoss: 1.238892\n",
      "Train Epoch: 7 [42880/50000 (86%)]\tLoss: 1.407292\n",
      "Train Epoch: 7 [43520/50000 (87%)]\tLoss: 1.340542\n",
      "Train Epoch: 7 [44160/50000 (88%)]\tLoss: 0.968160\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.339277\n",
      "Train Epoch: 7 [45440/50000 (91%)]\tLoss: 1.331283\n",
      "Train Epoch: 7 [46080/50000 (92%)]\tLoss: 1.478998\n",
      "Train Epoch: 7 [46720/50000 (93%)]\tLoss: 1.210022\n",
      "Train Epoch: 7 [47360/50000 (95%)]\tLoss: 1.414055\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 1.669992\n",
      "Train Epoch: 7 [48640/50000 (97%)]\tLoss: 1.273109\n",
      "Train Epoch: 7 [49280/50000 (98%)]\tLoss: 1.383706\n",
      "Train Epoch: 7 [49920/50000 (100%)]\tLoss: 1.588058\n",
      "\n",
      "Test set: Average loss: 1.2967, Accuracy: 5293/10000 (53%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.253626\n",
      "Train Epoch: 8 [640/50000 (1%)]\tLoss: 1.703210\n",
      "Train Epoch: 8 [1280/50000 (3%)]\tLoss: 1.279947\n",
      "Train Epoch: 8 [1920/50000 (4%)]\tLoss: 1.517097\n",
      "Train Epoch: 8 [2560/50000 (5%)]\tLoss: 1.288941\n",
      "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 1.335908\n",
      "Train Epoch: 8 [3840/50000 (8%)]\tLoss: 1.295032\n",
      "Train Epoch: 8 [4480/50000 (9%)]\tLoss: 1.532799\n",
      "Train Epoch: 8 [5120/50000 (10%)]\tLoss: 1.313673\n",
      "Train Epoch: 8 [5760/50000 (12%)]\tLoss: 1.554046\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.436588\n",
      "Train Epoch: 8 [7040/50000 (14%)]\tLoss: 1.426565\n",
      "Train Epoch: 8 [7680/50000 (15%)]\tLoss: 1.561166\n",
      "Train Epoch: 8 [8320/50000 (17%)]\tLoss: 1.394647\n",
      "Train Epoch: 8 [8960/50000 (18%)]\tLoss: 1.236322\n",
      "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 1.309336\n",
      "Train Epoch: 8 [10240/50000 (20%)]\tLoss: 1.429107\n",
      "Train Epoch: 8 [10880/50000 (22%)]\tLoss: 1.086107\n",
      "Train Epoch: 8 [11520/50000 (23%)]\tLoss: 1.294113\n",
      "Train Epoch: 8 [12160/50000 (24%)]\tLoss: 1.452600\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.606257\n",
      "Train Epoch: 8 [13440/50000 (27%)]\tLoss: 1.388177\n",
      "Train Epoch: 8 [14080/50000 (28%)]\tLoss: 1.152271\n",
      "Train Epoch: 8 [14720/50000 (29%)]\tLoss: 1.303759\n",
      "Train Epoch: 8 [15360/50000 (31%)]\tLoss: 1.204690\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 1.305907\n",
      "Train Epoch: 8 [16640/50000 (33%)]\tLoss: 1.253917\n",
      "Train Epoch: 8 [17280/50000 (35%)]\tLoss: 1.220571\n",
      "Train Epoch: 8 [17920/50000 (36%)]\tLoss: 1.462396\n",
      "Train Epoch: 8 [18560/50000 (37%)]\tLoss: 1.358772\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.325126\n",
      "Train Epoch: 8 [19840/50000 (40%)]\tLoss: 1.419937\n",
      "Train Epoch: 8 [20480/50000 (41%)]\tLoss: 1.177321\n",
      "Train Epoch: 8 [21120/50000 (42%)]\tLoss: 1.353774\n",
      "Train Epoch: 8 [21760/50000 (43%)]\tLoss: 1.353233\n",
      "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 1.374299\n",
      "Train Epoch: 8 [23040/50000 (46%)]\tLoss: 1.412722\n",
      "Train Epoch: 8 [23680/50000 (47%)]\tLoss: 1.532906\n",
      "Train Epoch: 8 [24320/50000 (49%)]\tLoss: 1.480268\n",
      "Train Epoch: 8 [24960/50000 (50%)]\tLoss: 1.201454\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.333114\n",
      "Train Epoch: 8 [26240/50000 (52%)]\tLoss: 1.507280\n",
      "Train Epoch: 8 [26880/50000 (54%)]\tLoss: 1.433174\n",
      "Train Epoch: 8 [27520/50000 (55%)]\tLoss: 1.325627\n",
      "Train Epoch: 8 [28160/50000 (56%)]\tLoss: 1.329724\n",
      "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 1.392537\n",
      "Train Epoch: 8 [29440/50000 (59%)]\tLoss: 1.241994\n",
      "Train Epoch: 8 [30080/50000 (60%)]\tLoss: 1.346225\n",
      "Train Epoch: 8 [30720/50000 (61%)]\tLoss: 1.220002\n",
      "Train Epoch: 8 [31360/50000 (63%)]\tLoss: 1.314600\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.385362\n",
      "Train Epoch: 8 [32640/50000 (65%)]\tLoss: 1.354692\n",
      "Train Epoch: 8 [33280/50000 (66%)]\tLoss: 1.511095\n",
      "Train Epoch: 8 [33920/50000 (68%)]\tLoss: 1.263236\n",
      "Train Epoch: 8 [34560/50000 (69%)]\tLoss: 1.290159\n",
      "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 1.356443\n",
      "Train Epoch: 8 [35840/50000 (72%)]\tLoss: 1.678229\n",
      "Train Epoch: 8 [36480/50000 (73%)]\tLoss: 1.058273\n",
      "Train Epoch: 8 [37120/50000 (74%)]\tLoss: 1.472125\n",
      "Train Epoch: 8 [37760/50000 (75%)]\tLoss: 1.448590\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.250776\n",
      "Train Epoch: 8 [39040/50000 (78%)]\tLoss: 1.420562\n",
      "Train Epoch: 8 [39680/50000 (79%)]\tLoss: 1.306203\n",
      "Train Epoch: 8 [40320/50000 (81%)]\tLoss: 1.250891\n",
      "Train Epoch: 8 [40960/50000 (82%)]\tLoss: 1.397247\n",
      "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 1.422056\n",
      "Train Epoch: 8 [42240/50000 (84%)]\tLoss: 1.352606\n",
      "Train Epoch: 8 [42880/50000 (86%)]\tLoss: 1.413060\n",
      "Train Epoch: 8 [43520/50000 (87%)]\tLoss: 1.286346\n",
      "Train Epoch: 8 [44160/50000 (88%)]\tLoss: 1.174041\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.401314\n",
      "Train Epoch: 8 [45440/50000 (91%)]\tLoss: 1.302375\n",
      "Train Epoch: 8 [46080/50000 (92%)]\tLoss: 1.367101\n",
      "Train Epoch: 8 [46720/50000 (93%)]\tLoss: 1.346383\n",
      "Train Epoch: 8 [47360/50000 (95%)]\tLoss: 1.369844\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 1.513208\n",
      "Train Epoch: 8 [48640/50000 (97%)]\tLoss: 1.344317\n",
      "Train Epoch: 8 [49280/50000 (98%)]\tLoss: 1.316912\n",
      "Train Epoch: 8 [49920/50000 (100%)]\tLoss: 1.489311\n",
      "\n",
      "Test set: Average loss: 1.3338, Accuracy: 5338/10000 (53%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.204098\n",
      "Train Epoch: 9 [640/50000 (1%)]\tLoss: 1.185871\n",
      "Train Epoch: 9 [1280/50000 (3%)]\tLoss: 1.361454\n",
      "Train Epoch: 9 [1920/50000 (4%)]\tLoss: 1.293654\n",
      "Train Epoch: 9 [2560/50000 (5%)]\tLoss: 1.137731\n",
      "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 1.288873\n",
      "Train Epoch: 9 [3840/50000 (8%)]\tLoss: 1.381475\n",
      "Train Epoch: 9 [4480/50000 (9%)]\tLoss: 1.395511\n",
      "Train Epoch: 9 [5120/50000 (10%)]\tLoss: 1.440469\n",
      "Train Epoch: 9 [5760/50000 (12%)]\tLoss: 1.066363\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.350011\n",
      "Train Epoch: 9 [7040/50000 (14%)]\tLoss: 1.164255\n",
      "Train Epoch: 9 [7680/50000 (15%)]\tLoss: 1.374658\n",
      "Train Epoch: 9 [8320/50000 (17%)]\tLoss: 1.265499\n",
      "Train Epoch: 9 [8960/50000 (18%)]\tLoss: 1.270541\n",
      "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 1.243914\n",
      "Train Epoch: 9 [10240/50000 (20%)]\tLoss: 1.498555\n",
      "Train Epoch: 9 [10880/50000 (22%)]\tLoss: 1.267454\n",
      "Train Epoch: 9 [11520/50000 (23%)]\tLoss: 1.456367\n",
      "Train Epoch: 9 [12160/50000 (24%)]\tLoss: 1.394689\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.501690\n",
      "Train Epoch: 9 [13440/50000 (27%)]\tLoss: 0.976924\n",
      "Train Epoch: 9 [14080/50000 (28%)]\tLoss: 1.262420\n",
      "Train Epoch: 9 [14720/50000 (29%)]\tLoss: 1.399631\n",
      "Train Epoch: 9 [15360/50000 (31%)]\tLoss: 1.515759\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 1.250492\n",
      "Train Epoch: 9 [16640/50000 (33%)]\tLoss: 1.206848\n",
      "Train Epoch: 9 [17280/50000 (35%)]\tLoss: 1.486230\n",
      "Train Epoch: 9 [17920/50000 (36%)]\tLoss: 1.311062\n",
      "Train Epoch: 9 [18560/50000 (37%)]\tLoss: 1.199799\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.149906\n",
      "Train Epoch: 9 [19840/50000 (40%)]\tLoss: 1.083144\n",
      "Train Epoch: 9 [20480/50000 (41%)]\tLoss: 1.190667\n",
      "Train Epoch: 9 [21120/50000 (42%)]\tLoss: 1.284983\n",
      "Train Epoch: 9 [21760/50000 (43%)]\tLoss: 1.291604\n",
      "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 1.148951\n",
      "Train Epoch: 9 [23040/50000 (46%)]\tLoss: 1.379778\n",
      "Train Epoch: 9 [23680/50000 (47%)]\tLoss: 1.457103\n",
      "Train Epoch: 9 [24320/50000 (49%)]\tLoss: 1.313604\n",
      "Train Epoch: 9 [24960/50000 (50%)]\tLoss: 1.333652\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.451316\n",
      "Train Epoch: 9 [26240/50000 (52%)]\tLoss: 1.540578\n",
      "Train Epoch: 9 [26880/50000 (54%)]\tLoss: 1.080291\n",
      "Train Epoch: 9 [27520/50000 (55%)]\tLoss: 1.523767\n",
      "Train Epoch: 9 [28160/50000 (56%)]\tLoss: 1.314308\n",
      "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 1.468515\n",
      "Train Epoch: 9 [29440/50000 (59%)]\tLoss: 1.290092\n",
      "Train Epoch: 9 [30080/50000 (60%)]\tLoss: 1.407853\n",
      "Train Epoch: 9 [30720/50000 (61%)]\tLoss: 1.202257\n",
      "Train Epoch: 9 [31360/50000 (63%)]\tLoss: 1.313576\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.335632\n",
      "Train Epoch: 9 [32640/50000 (65%)]\tLoss: 1.541671\n",
      "Train Epoch: 9 [33280/50000 (66%)]\tLoss: 1.387966\n",
      "Train Epoch: 9 [33920/50000 (68%)]\tLoss: 1.168540\n",
      "Train Epoch: 9 [34560/50000 (69%)]\tLoss: 1.115890\n",
      "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 1.499768\n",
      "Train Epoch: 9 [35840/50000 (72%)]\tLoss: 1.433257\n",
      "Train Epoch: 9 [36480/50000 (73%)]\tLoss: 1.529259\n",
      "Train Epoch: 9 [37120/50000 (74%)]\tLoss: 1.384255\n",
      "Train Epoch: 9 [37760/50000 (75%)]\tLoss: 1.333126\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.256931\n",
      "Train Epoch: 9 [39040/50000 (78%)]\tLoss: 1.145817\n",
      "Train Epoch: 9 [39680/50000 (79%)]\tLoss: 1.444676\n",
      "Train Epoch: 9 [40320/50000 (81%)]\tLoss: 1.441461\n",
      "Train Epoch: 9 [40960/50000 (82%)]\tLoss: 1.210613\n",
      "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 1.523702\n",
      "Train Epoch: 9 [42240/50000 (84%)]\tLoss: 1.280082\n",
      "Train Epoch: 9 [42880/50000 (86%)]\tLoss: 1.284025\n",
      "Train Epoch: 9 [43520/50000 (87%)]\tLoss: 1.443687\n",
      "Train Epoch: 9 [44160/50000 (88%)]\tLoss: 1.496385\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.461566\n",
      "Train Epoch: 9 [45440/50000 (91%)]\tLoss: 1.291386\n",
      "Train Epoch: 9 [46080/50000 (92%)]\tLoss: 1.534235\n",
      "Train Epoch: 9 [46720/50000 (93%)]\tLoss: 1.237387\n",
      "Train Epoch: 9 [47360/50000 (95%)]\tLoss: 1.063928\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 1.391955\n",
      "Train Epoch: 9 [48640/50000 (97%)]\tLoss: 1.307974\n",
      "Train Epoch: 9 [49280/50000 (98%)]\tLoss: 1.310457\n",
      "Train Epoch: 9 [49920/50000 (100%)]\tLoss: 1.289261\n",
      "\n",
      "Test set: Average loss: 1.2997, Accuracy: 5436/10000 (54%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.232277\n",
      "Train Epoch: 10 [640/50000 (1%)]\tLoss: 1.257159\n",
      "Train Epoch: 10 [1280/50000 (3%)]\tLoss: 1.321249\n",
      "Train Epoch: 10 [1920/50000 (4%)]\tLoss: 1.209664\n",
      "Train Epoch: 10 [2560/50000 (5%)]\tLoss: 1.280141\n",
      "Train Epoch: 10 [3200/50000 (6%)]\tLoss: 1.436096\n",
      "Train Epoch: 10 [3840/50000 (8%)]\tLoss: 1.308868\n",
      "Train Epoch: 10 [4480/50000 (9%)]\tLoss: 1.165501\n",
      "Train Epoch: 10 [5120/50000 (10%)]\tLoss: 1.553004\n",
      "Train Epoch: 10 [5760/50000 (12%)]\tLoss: 1.363936\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.407113\n",
      "Train Epoch: 10 [7040/50000 (14%)]\tLoss: 1.283738\n",
      "Train Epoch: 10 [7680/50000 (15%)]\tLoss: 1.320155\n",
      "Train Epoch: 10 [8320/50000 (17%)]\tLoss: 1.377242\n",
      "Train Epoch: 10 [8960/50000 (18%)]\tLoss: 1.505099\n",
      "Train Epoch: 10 [9600/50000 (19%)]\tLoss: 1.123302\n",
      "Train Epoch: 10 [10240/50000 (20%)]\tLoss: 1.237300\n",
      "Train Epoch: 10 [10880/50000 (22%)]\tLoss: 1.287226\n",
      "Train Epoch: 10 [11520/50000 (23%)]\tLoss: 1.134228\n",
      "Train Epoch: 10 [12160/50000 (24%)]\tLoss: 1.344174\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.117301\n",
      "Train Epoch: 10 [13440/50000 (27%)]\tLoss: 1.293050\n",
      "Train Epoch: 10 [14080/50000 (28%)]\tLoss: 1.336657\n",
      "Train Epoch: 10 [14720/50000 (29%)]\tLoss: 1.175341\n",
      "Train Epoch: 10 [15360/50000 (31%)]\tLoss: 1.026604\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 1.173298\n",
      "Train Epoch: 10 [16640/50000 (33%)]\tLoss: 1.535797\n",
      "Train Epoch: 10 [17280/50000 (35%)]\tLoss: 1.317354\n",
      "Train Epoch: 10 [17920/50000 (36%)]\tLoss: 1.394914\n",
      "Train Epoch: 10 [18560/50000 (37%)]\tLoss: 1.321614\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.249305\n",
      "Train Epoch: 10 [19840/50000 (40%)]\tLoss: 1.225548\n",
      "Train Epoch: 10 [20480/50000 (41%)]\tLoss: 1.034337\n",
      "Train Epoch: 10 [21120/50000 (42%)]\tLoss: 1.241642\n",
      "Train Epoch: 10 [21760/50000 (43%)]\tLoss: 1.322651\n",
      "Train Epoch: 10 [22400/50000 (45%)]\tLoss: 1.284799\n",
      "Train Epoch: 10 [23040/50000 (46%)]\tLoss: 1.277918\n",
      "Train Epoch: 10 [23680/50000 (47%)]\tLoss: 1.179146\n",
      "Train Epoch: 10 [24320/50000 (49%)]\tLoss: 1.314719\n",
      "Train Epoch: 10 [24960/50000 (50%)]\tLoss: 1.274532\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.268339\n",
      "Train Epoch: 10 [26240/50000 (52%)]\tLoss: 1.274453\n",
      "Train Epoch: 10 [26880/50000 (54%)]\tLoss: 1.448182\n",
      "Train Epoch: 10 [27520/50000 (55%)]\tLoss: 1.440046\n",
      "Train Epoch: 10 [28160/50000 (56%)]\tLoss: 1.303756\n",
      "Train Epoch: 10 [28800/50000 (58%)]\tLoss: 1.332717\n",
      "Train Epoch: 10 [29440/50000 (59%)]\tLoss: 1.236418\n",
      "Train Epoch: 10 [30080/50000 (60%)]\tLoss: 1.189566\n",
      "Train Epoch: 10 [30720/50000 (61%)]\tLoss: 1.374863\n",
      "Train Epoch: 10 [31360/50000 (63%)]\tLoss: 1.110807\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.219985\n",
      "Train Epoch: 10 [32640/50000 (65%)]\tLoss: 1.455114\n",
      "Train Epoch: 10 [33280/50000 (66%)]\tLoss: 1.554600\n",
      "Train Epoch: 10 [33920/50000 (68%)]\tLoss: 1.323912\n",
      "Train Epoch: 10 [34560/50000 (69%)]\tLoss: 1.111079\n",
      "Train Epoch: 10 [35200/50000 (70%)]\tLoss: 1.669731\n",
      "Train Epoch: 10 [35840/50000 (72%)]\tLoss: 1.237319\n",
      "Train Epoch: 10 [36480/50000 (73%)]\tLoss: 1.083202\n",
      "Train Epoch: 10 [37120/50000 (74%)]\tLoss: 1.273075\n",
      "Train Epoch: 10 [37760/50000 (75%)]\tLoss: 1.304355\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.286739\n",
      "Train Epoch: 10 [39040/50000 (78%)]\tLoss: 1.439210\n",
      "Train Epoch: 10 [39680/50000 (79%)]\tLoss: 1.483707\n",
      "Train Epoch: 10 [40320/50000 (81%)]\tLoss: 1.410451\n",
      "Train Epoch: 10 [40960/50000 (82%)]\tLoss: 1.337623\n",
      "Train Epoch: 10 [41600/50000 (83%)]\tLoss: 1.070549\n",
      "Train Epoch: 10 [42240/50000 (84%)]\tLoss: 1.268845\n",
      "Train Epoch: 10 [42880/50000 (86%)]\tLoss: 1.091817\n",
      "Train Epoch: 10 [43520/50000 (87%)]\tLoss: 1.227689\n",
      "Train Epoch: 10 [44160/50000 (88%)]\tLoss: 1.480410\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.217325\n",
      "Train Epoch: 10 [45440/50000 (91%)]\tLoss: 1.609054\n",
      "Train Epoch: 10 [46080/50000 (92%)]\tLoss: 1.410289\n",
      "Train Epoch: 10 [46720/50000 (93%)]\tLoss: 1.351941\n",
      "Train Epoch: 10 [47360/50000 (95%)]\tLoss: 1.287240\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 1.363048\n",
      "Train Epoch: 10 [48640/50000 (97%)]\tLoss: 1.164101\n",
      "Train Epoch: 10 [49280/50000 (98%)]\tLoss: 1.219947\n",
      "Train Epoch: 10 [49920/50000 (100%)]\tLoss: 1.206510\n",
      "\n",
      "Test set: Average loss: 1.2529, Accuracy: 5625/10000 (56%)\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ceil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-249d55658ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0mvisual_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualizedResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m# Visualize training curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m \u001b[0mvisual_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_records\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0mvisual_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_records\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-249d55658ee4>\u001b[0m in \u001b[0;36mtraining_curve\u001b[0;34m(self, epoches, train_loss_records, test_loss_records)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_records\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_records\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoches'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ceil' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training settings\n",
    "# for terminal use. In notebook, you can't parse arguments\n",
    "class args:\n",
    "    cuda = False\n",
    "    batch_size = 64\n",
    "    test_batch_size = 1000\n",
    "    epochs = 10\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    no_cuda = False\n",
    "    seed = 1\n",
    "    log_interval = 10\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # TODO: define your network here\n",
    "        self.block_conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.block_conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # TODO: replace fc using conv\n",
    "        self.block_fc_1 = nn.Sequential(\n",
    "            nn.Linear(16*25, 120),\n",
    "            nn.Dropout2d()\n",
    "        )\n",
    "        # TODO: replace fc using conv\n",
    "        self.block_fc_2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Dropout2d()\n",
    "        )\n",
    "        # TODO: replace fc using conv\n",
    "        self.fc_3 = nn.Linear(84, 10)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        # Initialize parameters\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                # m.weight.data.normal_(0, math.sqrt(2. /n))\n",
    "                # if m.bias is not None:\n",
    "                #     m.bias.zero_()\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m = m\n",
    "                # m.weight.data.fill_(1)\n",
    "                # m.bias.data.zero_()\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m = m\n",
    "                # m.weight.data.normal_(0, 0.001)\n",
    "                # if m.bias is not None:\n",
    "                #    m.bias.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        x = self.block_conv_1(x)\n",
    "        x = self.block_conv_2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.block_fc_1(x)\n",
    "        x = self.block_fc_2(x)\n",
    "        x = self.fc_3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Feature extractor\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, model, layer_names):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self._model = model\n",
    "        self._layer_names = set(layer_names)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = dict()\n",
    "        for name, module in _model._modules.iteritems():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                x = x.view(x.size(0), -1)\n",
    "            x = module(x)\n",
    "            if name in self._layer_names:\n",
    "                out[name] = x\n",
    "        return out\n",
    "\n",
    "# Vesualize training results and trained filters\n",
    "class VisualizedResult():\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "    def training_curve(self, epoches, train_loss_records, test_loss_records):\n",
    "        plt.axis([1, epoches, 0, math.ceil(max(train_loss_records, test_loss_records) * 1.2)])\n",
    "        plt.xlabel('Epoches')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Curve')\n",
    "        plt.plot(range(1, epoches+1), train_loss_records, 'b-', range(1, epoches+1), test_loss_records, 'r-')\n",
    "        plt.show()\n",
    "    def accuracy_curve(self, epoches, accuracy_records):\n",
    "        plt.axis([1, epoches, 0, math.ceil(max(accuracy_records)*1.2)])\n",
    "        plt.xlabel('Epoches')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Accuracy Curve')\n",
    "        plt.plot(range(1, epoches+1), accuracy_records, '-')\n",
    "        plt.show()\n",
    "    def conv_filter(self, layer_names):\n",
    "        feature_extractor = FeatureExtractor(model, layer_names)\n",
    "\n",
    "\n",
    "\n",
    "model = Net()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "# TODO: other optimizers\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "train_loss_records = list()\n",
    "test_loss_records = list()\n",
    "accuracy_records = list()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)   # is it true to use such a loss over cross-entropy loss? \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.data[0]\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "    # Average training loss for this epoch\n",
    "    train_loss_records.append(train_loss / len(train_loader))\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target).data[0]\n",
    "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss = test_loss\n",
    "    test_loss /= len(test_loader) # loss function already averages over batch size\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "    test_loss_records.append(test_loss)\n",
    "    accuracy_records.append(accuracy)\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "visual_result = VisualizedResult(model)\n",
    "# Visualize training curve\n",
    "visual_result.training_curve(args.epochs, train_loss_records, test_loss_records)\n",
    "#\n",
    "visual_result.accuracy_curve(args.epochs, accuracy_records)\n",
    "# Visualize trained filter on the 1st Conv layer\n",
    "visual_result.conv_filter(['conv_1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
